<meta charset="UTF-8">
<!-- TÃTULO ANIMADO -->
<meta charset="UTF-8">
<h1 align="center">
    <img src="https://readme-typing-svg.herokuapp.com/?font=Righteous&size=35&center=true&vCenter=true&width=800&height=70&duration=4000&lines=ClasificaciÃ³n:+PredicciÃ³n+de+Riesgo+Crediticio" />
</h1>

<h3 align="center">ğŸ“š Curso: Machine Learning ğŸ“š</h3>

<div align="center">
    <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" />
    <img src="https://img.shields.io/badge/Jupyter-F37626?style=for-the-badge&logo=jupyter&logoColor=white" />
    <img src="https://img.shields.io/badge/scikit--learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white" />
    <img src="https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=numpy&logoColor=white" />
    <img src="https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white" />
</div>

## ğŸ“‘ Tabla de Contenidos
1. [InformaciÃ³n del Proyecto](#informacion-del-proyecto)
2. [Estructura del Proyecto](#estructura-del-proyecto)
3. [MetodologÃ­a Implementada](#metodologia-implementada)
4. [Resultados y Experimentos](#resultados-y-experimentos)
5. [EjecuciÃ³n del Proyecto](#ejecucion-del-proyecto)
6. [CaracterÃ­sticas del Sistema](#caracteristicas-del-sistema)

---

## ğŸ“ InformaciÃ³n del Proyecto
<a name="informacion-del-proyecto"></a>

Este proyecto implementa un sistema de **clasificaciÃ³n multiclase** para predecir el nivel de riesgo de impago en prÃ©stamos comerciales. El objetivo es clasificar clientes en 3 categorÃ­as de riesgo:
- **0**: Riesgo Bajo
- **1**: Riesgo Medio  
- **2**: Riesgo Alto

### Objetivos del Proyecto
- **ImplementaciÃ³n de Algoritmos ML Propios**: Desarrollo desde cero de 3 algoritmos de machine learning para clasificaciÃ³n multiclase
- **AnÃ¡lisis Exploratorio Exhaustivo**: ComprensiÃ³n profunda del dataset y sus patrones subyacentes
- **OptimizaciÃ³n y EvaluaciÃ³n**: Sistema robusto de mÃ©tricas y optimizaciÃ³n de hiperparÃ¡metros
- **Consideraciones de Negocio**: Enfoque en minimizar costos de clasificaciÃ³n errÃ³nea en contexto financiero

### CaracterÃ­sticas Clave
- **Dataset**: 20,000 instancias con 35 caracterÃ­sticas financieras y demogrÃ¡ficas
- **Implementaciones Propias**: 3 algoritmos ML desarrollados desde cero (Logistic Regression, SVM, Random Forest)
- **Algoritmo de Referencia**: KNN usando Sklearn como baseline
- **TÃ©cnicas Avanzadas**: Feature engineering, selecciÃ³n de caracterÃ­sticas, validaciÃ³n cruzada
- **Visualizaciones**: Plots generados con asistencia de IA para anÃ¡lisis exploratorio

### TecnologÃ­as Utilizadas
- **Lenguaje**: Python 3.11+
- **LibrerÃ­as Principales**: NumPy, Pandas, Matplotlib, Seaborn
- **Notebooks**: Jupyter para desarrollo interactivo
- **OptimizaciÃ³n**: Operaciones vectorizadas para eficiencia computacional

---

<details>
  <summary><strong>ğŸ—ï¸ Estructura del Proyecto</strong></summary>
  <a name="estructura-del-proyecto"></a>

```
P1-Classification/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                          # Datos originales
â”‚   â”‚   â”œâ”€â”€ datos_entrenamiento_riesgo.csv
â”‚   â”‚   â””â”€â”€ datos_prueba_riesgo.csv
â”‚   â””â”€â”€ processed/                    # Datos procesados y transformados
â”‚       â”œâ”€â”€ feature_names.txt
â”‚       â”œâ”€â”€ preprocessing_metadata.json
â”‚       â””â”€â”€ *.csv, *.npy             # Datos entrenamiento/test procesados
â”œâ”€â”€ notebooks/                        # ğŸ“Š NOTEBOOKS PRINCIPALES
â”‚   â”œâ”€â”€ 01_eda.ipynb                 # AnÃ¡lisis Exploratorio de Datos
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb        # Pipeline de Preprocesamiento
â”‚   â””â”€â”€ 03_modeling.ipynb            # Entrenamiento y EvaluaciÃ³n
â”œâ”€â”€ src/                             # CÃ³digo fuente modular
â”‚   â”œâ”€â”€ data/loader.py              # Utilidades de carga de datos
â”‚   â”œâ”€â”€ models/                     # ğŸ¤– IMPLEMENTACIONES PROPIAS
â”‚   â”‚   â”œâ”€â”€ logistic_regression.py  # RegresiÃ³n LogÃ­stica Multinomial
â”‚   â”‚   â”œâ”€â”€ svm.py                  # Support Vector Machine
â”‚   â”‚   â”œâ”€â”€ random_forest.py        # Random Forest
â”‚   â”‚   â””â”€â”€ base_classifier.py      # Clase base para modelos
â”‚   â”œâ”€â”€ evaluation/metrics.py       # Sistema de mÃ©tricas
â”‚   â””â”€â”€ utils/                      # Utilidades de optimizaciÃ³n
â”œâ”€â”€ experiments/                     # ğŸ“ˆ RESULTADOS Y EXPERIMENTOS
â”‚   â”œâ”€â”€ best_hyperparameters.json
â”‚   â”œâ”€â”€ optimization_summary.csv
â”‚   â””â”€â”€ feature_importance_*.csv
â””â”€â”€ tests/                          # Pruebas unitarias
```

### DescripciÃ³n de Directorios:
- **ğŸ“ data/**: Contiene todos los datasets tanto originales como procesados
- **ğŸ“ notebooks/**: Notebooks principales con todo el anÃ¡lisis y experimentaciÃ³n
- **ğŸ“ src/**: CÃ³digo fuente modular y reutilizable del proyecto
- **ğŸ“ experiments/**: Resultados de experimentos, mÃ©tricas y configuraciones Ã³ptimas
- **ğŸ“ tests/**: Pruebas unitarias para validar el correcto funcionamiento

</details>

---

<details>
  <summary><strong>ğŸ”¬ MetodologÃ­a Implementada</strong></summary>
  <a name="metodologia-implementada"></a>

### 1. AnÃ¡lisis Exploratorio de Datos (EDA)
**ğŸ“ Ver**: `notebooks/01_eda.ipynb`

- **AnÃ¡lisis estadÃ­stico** completo de las 35 variables
- **Visualizaciones** de distribuciones y correlaciones (*generadas con asistencia de IA*)
- **DetecciÃ³n de outliers** y patrones en los datos
- **AnÃ¡lisis de balanceamiento** de clases objetivo

### 2. Preprocesamiento de Datos
**ğŸ“ Ver**: `notebooks/02_preprocessing.ipynb`

- **Limpieza de datos**: Tratamiento de valores faltantes
- **Transformaciones**:
  - NormalizaciÃ³n Z-score para variables numÃ©ricas
  - Encoding de variables categÃ³ricas
- **Feature Engineering**: CreaciÃ³n de ratios financieros y scores compuestos
- **SelecciÃ³n de caracterÃ­sticas**: EliminaciÃ³n de features redundantes
- **Resultado**: 37 caracterÃ­sticas finales para modelado

### 3. ImplementaciÃ³n de Modelos
**ğŸ“ Ver**: `notebooks/03_modeling.ipynb` y `src/models/`

#### ğŸ¤– Algoritmos Implementados Desde Cero:

1. **RegresiÃ³n LogÃ­stica Multinomial** (`src/models/logistic_regression.py`)
   - ImplementaciÃ³n con regularizaciÃ³n L1/L2
   - OptimizaciÃ³n con gradiente descendente
   - Softmax para clasificaciÃ³n multiclase
   - **Complejidad**: O(n Ã— m Ã— iterations)

2. **Support Vector Machine** (`src/models/svm.py`)
   - Enfoque One-vs-Rest para multiclase
   - Kernels: Lineal y RBF (Radial Basis Function)
   - OptimizaciÃ³n del margen mÃ¡ximo
   - **Complejidad**: O(nÂ³) para entrenamiento

3. **Random Forest** (`src/models/random_forest.py`)
   - Ensemble de Ã¡rboles de decisiÃ³n
   - Bagging y votaciÃ³n por mayorÃ­a
   - SelecciÃ³n aleatoria de caracterÃ­sticas
   - **Complejidad**: O(n Ã— log(n) Ã— trees)

#### ğŸ“š Algoritmo de Referencia (Sklearn):
4. **K-Nearest Neighbors (KNN)** - Usado como baseline de comparaciÃ³n

### 4. EvaluaciÃ³n y OptimizaciÃ³n
**ğŸ“ Ver resultados en**: `experiments/`

#### MÃ©tricas de EvaluaciÃ³n:
- **Accuracy**: PrecisiÃ³n global del modelo
- **Precision, Recall, F1-Score**: Por clase y promediadas
- **Matriz de ConfusiÃ³n**: AnÃ¡lisis detallado de errores
- **ValidaciÃ³n Cruzada**: 5-fold estratificada

#### OptimizaciÃ³n de HiperparÃ¡metros:
- **Grid Search** para exploraciÃ³n exhaustiva
- **SelecciÃ³n automÃ¡tica** de mejores parÃ¡metros
- **Guardado de configuraciones** Ã³ptimas en `experiments/best_hyperparameters.json`

</details>

---

<details>
  <summary><strong>ğŸ“Š Resultados y Experimentos</strong></summary>
  <a name="resultados-y-experimentos"></a>

### ğŸ¯ Notebooks Principales (Ejecutar en orden):
1. **`notebooks/01_eda.ipynb`** 
   - AnÃ¡lisis estadÃ­stico completo del dataset
   - Visualizaciones de distribuciones y correlaciones
   - DetecciÃ³n de patrones y outliers
   
2. **`notebooks/02_preprocessing.ipynb`** 
   - Pipeline completo de limpieza de datos
   - Transformaciones y feature engineering
   - ValidaciÃ³n de calidad de datos
   
3. **`notebooks/03_modeling.ipynb`** 
   - Entrenamiento de todos los modelos
   - EvaluaciÃ³n comparativa y mÃ©tricas
   - OptimizaciÃ³n de hiperparÃ¡metros

### ğŸ“ˆ Archivos de Resultados:
- **`experiments/optimization_summary.csv`** 
  - ComparaciÃ³n de rendimiento de todos los modelos
  - MÃ©tricas de evaluaciÃ³n (Accuracy, F1-Score, Precision, Recall)
  
- **`experiments/best_hyperparameters.json`** 
  - Configuraciones Ã³ptimas encontradas para cada modelo
  - ParÃ¡metros de regularizaciÃ³n y arquitectura
  
- **`experiments/feature_importance_*.csv`** 
  - AnÃ¡lisis de importancia de caracterÃ­sticas
  - Rankings de features mÃ¡s relevantes para la predicciÃ³n

### ğŸ” Datos Procesados:
- **`data/processed/`** 
  - Datasets limpios y transformados
  - Archivos en formatos CSV y NumPy (.npy)
  - Metadata de preprocesamiento

### ğŸ¯ Resultados Esperados:
- **Modelos Entrenados**: 4 algoritmos diferentes comparados
- **MÃ©tricas de EvaluaciÃ³n**: Precision, Recall, F1-Score, Accuracy
- **Visualizaciones**: Matrices de confusiÃ³n y curvas de aprendizaje
- **Interpretabilidad**: Feature importance y anÃ¡lisis de errores

</details>

---

<details>
  <summary><strong>ğŸš€ EjecuciÃ³n del Proyecto</strong></summary>
  <a name="ejecucion-del-proyecto"></a>

### Requisitos del Sistema:
```bash
# Instalar dependencias
pip install -r requirements.txt

# Versiones recomendadas
Python >= 3.11
NumPy >= 1.24.0
Pandas >= 2.0.0
Matplotlib >= 3.7.0
Seaborn >= 0.12.0
Jupyter >= 1.0.0
```

### Pasos de EjecuciÃ³n:

1. **ConfiguraciÃ³n del Entorno**:
   ```bash
   # Clonar el repositorio
   git clone https://github.com/ML-2025-2-UTEC/P1-Classification.git
   cd P1-Classification
   
   # Crear entorno virtual (recomendado)
   python -m venv venv
   source venv/bin/activate  # En Windows: venv\Scripts\activate
   
   # Instalar dependencias
   pip install -r requirements.txt
   ```

2. **AnÃ¡lisis Exploratorio**: 
   - Ejecutar `notebooks/01_eda.ipynb`
   - Tiempo estimado: 10-15 minutos
   - Genera visualizaciones y estadÃ­sticas descriptivas

3. **Preprocesamiento**: 
   - Ejecutar `notebooks/02_preprocessing.ipynb`
   - Tiempo estimado: 5-10 minutos
   - Procesa y guarda datos limpios en `data/processed/`

4. **Modelado Completo**: 
   - Ejecutar `notebooks/03_modeling.ipynb`
   - Tiempo estimado: 20-30 minutos
   - Entrena todos los modelos y genera resultados

### Resultados Esperados:
- **Archivos generados** en `experiments/` con mÃ©tricas y configuraciones
- **Modelos entrenados** guardados para reutilizaciÃ³n
- **Visualizaciones** de rendimiento y anÃ¡lisis comparativo
- **Datasets procesados** en `data/processed/` para futuras ejecuciones

</details>

---

<details>
  <summary><strong>ğŸ“ CaracterÃ­sticas del Sistema</strong></summary>
  <a name="caracteristicas-del-sistema"></a>

### Modelos Implementados:
- âœ… **3 algoritmos propios**: Logistic Regression, SVM, Random Forest
- âœ… **1 algoritmo sklearn**: KNN (baseline)
- âœ… **Sistema completo** de evaluaciÃ³n y optimizaciÃ³n

### Arquitectura del CÃ³digo:
- ğŸ”§ **DiseÃ±o modular**: SeparaciÃ³n clara entre carga de datos, modelos, evaluaciÃ³n
- ğŸ“Š **Visualizaciones comprehensivas**: Plots generados con asistencia de IA
- âš¡ **Operaciones vectorizadas**: NumPy para mÃ¡xima eficiencia computacional
- ğŸ’¾ **Persistencia inteligente**: Guardado automÃ¡tico de modelos y configuraciones
- ğŸ§ª **Pruebas unitarias**: ValidaciÃ³n automÃ¡tica de funcionalidades crÃ­ticas

### Consideraciones de Negocio:
- ğŸ¯ **MinimizaciÃ³n de riesgo**: Foco en reducir falsos negativos (Altoâ†’Bajo riesgo)
- ğŸ“ˆ **AnÃ¡lisis de costos**: EvaluaciÃ³n del impacto financiero de errores de clasificaciÃ³n
- ğŸ” **Interpretabilidad**: Feature importance y anÃ¡lisis de decisiones del modelo
- ï¿½ **Compliance**: DocumentaciÃ³n exhaustiva para auditorÃ­a y regulaciÃ³n

### Optimizaciones TÃ©cnicas:
- **ParalelizaciÃ³n**: Operaciones matriciales optimizadas
- **Memory Management**: Uso eficiente de memoria para datasets grandes
- **Scalabilidad**: Arquitectura preparada para datasets mÃ¡s grandes
- **Reproducibilidad**: Seeds fijos y logging de experimentos

### MÃ©tricas de Calidad:
- **Cobertura de cÃ³digo**: Pruebas unitarias para funciones crÃ­ticas
- **DocumentaciÃ³n**: Docstrings completos y comentarios explicativos
- **EstÃ¡ndares**: PEP 8 y mejores prÃ¡cticas de Python
- **Versionado**: Control de versiones con Git para seguimiento de cambios

</details>

---

## ğŸ”— Referencias y CrÃ©ditos

### TecnologÃ­as Utilizadas:
- **Python**: Lenguaje principal del proyecto
- **NumPy**: Operaciones matriciales y vectorizadas
- **Pandas**: ManipulaciÃ³n y anÃ¡lisis de datos
- **Matplotlib/Seaborn**: VisualizaciÃ³n de datos
- **Jupyter**: Desarrollo interactivo y documentaciÃ³n

### Agradecimientos:
- **Visualizaciones**: Los plots y grÃ¡ficos fueron generados con asistencia de IA para optimizar la presentaciÃ³n de datos
- **DocumentaciÃ³n**: Inspirado en mejores prÃ¡cticas de documentaciÃ³n de proyectos ML

### Dataset:
- Datos sintÃ©ticos de riesgo crediticio con 20,000 instancias
- 35 caracterÃ­sticas financieras y demogrÃ¡ficas
- 3 clases de riesgo: Bajo (0), Medio (1), Alto (2)

<div align="center">
    <img src="https://skillicons.dev/icons?i=python,jupyter,numpy,matplotlib" />
</div>

---

<div align="center">
    <img src="https://img.shields.io/badge/Status-Completed-success?style=for-the-badge" />
    <img src="https://img.shields.io/badge/ML-Classification-blue?style=for-the-badge" />
    <img src="https://img.shields.io/badge/Python-3.11+-yellow?style=for-the-badge" />
</div>