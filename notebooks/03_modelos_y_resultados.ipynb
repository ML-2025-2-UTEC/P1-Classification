{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: Experimento Completo de Modelado y Evaluación\n",
    "\n",
    "Este notebook orquesta un pipeline de modelado de principio a fin, incluyendo:\n",
    "1. **Carga y Preprocesamiento de Datos en Memoria**: Carga los datos crudos y aplica el pipeline de transformación completo.\n",
    "2. **Búsqueda de Hiperparámetros**: Utiliza Grid Search manual para encontrar los mejores parámetros para cada modelo.\n",
    "3. **Entrenamiento y Calibración**: Entrena cada modelo con sus parámetros óptimos y calibra el SVM.\n",
    "4. **Evaluación Exhaustiva**: Evalúa los modelos finales en el conjunto de prueba usando un conjunto completo de métricas.\n",
    "5. **Comparación de Resultados**: Presenta una tabla resumen para comparar el rendimiento de todos los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# Añadir la carpeta 'src' al path\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "\n",
    "# Módulos del proyecto\n",
    "from data.loader import cargar_csv_crudo\n",
    "from features.transformers_manual import ImputadorNumericoMediana, ImputadorCategoricoModa, EscaladorEstandarManual, OneHotManual\n",
    "from models.algorithms_manual import RegresionLogisticaManual, RandomForestManual, SVMManual\n",
    "from models.knn_wrapper import crear_pipeline_knn\n",
    "from evaluation.cv_manual import StratifiedKFoldManual, grid_search_manual\n",
    "from evaluation.metrics_manual import (\n",
    "    matriz_confusion_manual, balanced_accuracy_manual, precision_recall_f1_por_clase, \n",
    "    macro_f1_score, weighted_f1_score, roc_auc_manual, pr_auc_manual\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones Auxiliares de Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_matriz_confusion(matriz_conf, etiquetas_clases, nombre_modelo):\n",
    "    \"\"\"Genera un heatmap de la matriz de confusión.\"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(matriz_conf, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=etiquetas_clases, yticklabels=etiquetas_clases)\n",
    "    plt.title(f'Matriz de Confusión para {nombre_modelo}')\n",
    "    plt.ylabel('Etiqueta Verdadera')\n",
    "    plt.xlabel('Etiqueta Predicha')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pipeline de Carga y Preprocesamiento de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos desde: e:\\06. Sexto Ciclo\\01. Machine Learning\\07. Workspace\\06S03. Proyecto 01\\06C_Machine_06S01_Clasification\\data\\raw\\datos_entrenamiento_riesgo.csv\n",
      "Cargando datos desde: e:\\06. Sexto Ciclo\\01. Machine Learning\\07. Workspace\\06S03. Proyecto 01\\06C_Machine_06S01_Clasification\\data\\raw\\datos_prueba_riesgo.csv\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "El parámetro 'variables' debe ser una lista o tupla.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m X_train_scaled, y_train, X_test_scaled, y_test, feature_names\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# Ejecutar el pipeline\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m X_train, y_train, X_test, y_test, feature_names = \u001b[43mpipeline_preprocesamiento_completo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mpipeline_preprocesamiento_completo\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     21\u001b[39m X_train_imp = imputador_num.transform(X_train_raw)\n\u001b[32m     22\u001b[39m X_test_imp = imputador_num.transform(X_test_raw)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m imputador_cat = \u001b[43mImputadorCategoricoModa\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcat_cols\u001b[49m\u001b[43m)\u001b[49m.fit(X_train_imp)\n\u001b[32m     24\u001b[39m X_train_imp = imputador_cat.transform(X_train_imp)\n\u001b[32m     25\u001b[39m X_test_imp = imputador_cat.transform(X_test_imp)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\06. Sexto Ciclo\\01. Machine Learning\\07. Workspace\\06S03. Proyecto 01\\06C_Machine_06S01_Clasification\\src\\features\\transformers_manual.py:65\u001b[39m, in \u001b[36mImputadorCategoricoModa.__init__\u001b[39m\u001b[34m(self, variables)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, variables=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(variables, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m variables \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mEl parámetro \u001b[39m\u001b[33m'\u001b[39m\u001b[33mvariables\u001b[39m\u001b[33m'\u001b[39m\u001b[33m debe ser una lista o tupla.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     66\u001b[39m     \u001b[38;5;28mself\u001b[39m.variables = variables\n\u001b[32m     67\u001b[39m     \u001b[38;5;28mself\u001b[39m.imputadores_ = {}\n",
      "\u001b[31mValueError\u001b[39m: El parámetro 'variables' debe ser una lista o tupla."
     ]
    }
   ],
   "source": [
    "def pipeline_preprocesamiento_completo():\n",
    "    # Carga\n",
    "    df_train = cargar_csv_crudo('datos_entrenamiento_riesgo.csv')\n",
    "    df_test = cargar_csv_crudo('datos_prueba_riesgo.csv')\n",
    "    \n",
    "    # Separación X, y\n",
    "    X_train_raw = df_train.drop('nivel_riesgo', axis=1)\n",
    "    y_train_raw = df_train['nivel_riesgo']\n",
    "    X_test_raw = df_test.drop('nivel_riesgo', axis=1)\n",
    "    y_test_raw = df_test['nivel_riesgo']\n",
    "    \n",
    "    # Codificar Target\n",
    "    mapa_target = {'Bajo': 0, 'Medio': 1, 'Alto': 2}\n",
    "    y_train = y_train_raw.map(mapa_target).values\n",
    "    y_test = y_test_raw.map(mapa_target).values\n",
    "    \n",
    "    # Imputación\n",
    "    num_cols = list(X_train_raw.select_dtypes(include=np.number).columns)\n",
    "    cat_cols = list(X_train_raw.select_dtypes(include='object').columns)\n",
    "\n",
    "    imputador_num = ImputadorNumericoMediana(variables=num_cols).fit(X_train_raw)\n",
    "    X_train_imp = imputador_num.transform(X_train_raw)\n",
    "    X_test_imp = imputador_num.transform(X_test_raw)\n",
    "\n",
    "    imputador_cat = ImputadorCategoricoModa(variables=cat_cols).fit(X_train_imp)\n",
    "    X_train_imp = imputador_cat.transform(X_train_imp)\n",
    "    X_test_imp = imputador_cat.transform(X_test_imp)\n",
    "    \n",
    "    # One-Hot Encoding\n",
    "    onehot = OneHotManual(variables=cat_cols, drop_last=True).fit(X_train_imp)\n",
    "    X_train_oh = onehot.transform(X_train_imp)\n",
    "    X_test_oh = onehot.transform(X_test_imp)\n",
    "    \n",
    "    # Alineación de columnas\n",
    "    train_cols, test_cols = set(X_train_oh.columns), set(X_test_oh.columns)\n",
    "    for col in (train_cols - test_cols):\n",
    "        X_test_oh[col] = 0\n",
    "    X_test_oh = X_test_oh[X_train_oh.columns]\n",
    "    \n",
    "    # Escalado\n",
    "    feature_names = X_train_oh.columns\n",
    "    escalador = EscaladorEstandarManual().fit(X_train_oh)\n",
    "    X_train_scaled = escalador.transform(X_train_oh).values\n",
    "    X_test_scaled = escalador.transform(X_test_oh).values\n",
    "    \n",
    "    return X_train_scaled, y_train, X_test_scaled, y_test, feature_names\n",
    "\n",
    "\n",
    "# Ejecutar el pipeline\n",
    "X_train, y_train, X_test, y_test, feature_names = pipeline_preprocesamiento_completo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Experimento de Modelado\n",
    "\n",
    "Ahora definimos los modelos, sus rejillas de hiperparámetros y ejecutamos el ciclo de entrenamiento y evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos_a_probar = {\n",
    "    'RegresionLogistica': {\n",
    "        'clase': RegresionLogisticaManual,\n",
    "        'rejilla': {'tasa_aprendizaje': [0.01, 0.1], 'C': [1, 10], 'epocas': [500]},\n",
    "        'calibrar': False\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'clase': RandomForestManual,\n",
    "        'rejilla': {'n_estimadores': [50, 100], 'max_profundidad': [5, 10]},\n",
    "        'calibrar': False\n",
    "    },\n",
    "    'SVM': {\n",
    "        'clase': SVMManual,\n",
    "        'rejilla': {'tasa_aprendizaje': [0.001, 0.01], 'C': [1, 10]},\n",
    "        'calibrar': True # SVM necesita calibración para probabilidades\n",
    "    },\n",
    "    'KNN': {\n",
    "        'clase': crear_pipeline_knn, # Es una función que devuelve un pipeline\n",
    "        'rejilla': {'n_neighbors': [5, 11], 'weights': ['uniform', 'distance']},\n",
    "        'calibrar': False\n",
    "    }\n",
    "}\n",
    "\n",
    "resultados_finales = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nombre_modelo, config in modelos_a_probar.items():\n",
    "    print(f\"\\n{'='*20} PROCESANDO MODELO: {nombre_modelo} {'='*20}\")\n",
    "    \n",
    "    # Búsqueda de hiperparámetros\n",
    "    cv = StratifiedKFoldManual(n_splits=3, shuffle=True, random_state=42)\n",
    "    mejores_params, _ = grid_search_manual(\n",
    "        estimador_clase=config['clase'],\n",
    "        rejilla_parametros=config['rejilla'],\n",
    "        X=X_train, y=y_train, cv=cv\n",
    "    )\n",
    "    \n",
    "    # Entrenamiento del modelo final\n",
    "    print(f\"Entrenando {nombre_modelo} con los mejores parámetros: {mejores_params}\")\n",
    "    modelo_final = config['clase'](**mejores_params)\n",
    "    modelo_final.fit(X_train, y_train)\n",
    "    \n",
    "    # Calibración y predicción de probabilidades\n",
    "    if config['calibrar']:\n",
    "        print(\"Calibrando modelo SVM...\")\n",
    "        scores_calibracion = modelo_final.predict_scores(X_train)\n",
    "        calibrador = RegresionLogisticaManual(epocas=100).fit(scores_calibracion, y_train)\n",
    "        scores_test = modelo_final.predict_scores(X_test)\n",
    "        y_pred_proba = calibrador.predict_proba(scores_test)\n",
    "        y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "    else:\n",
    "        y_pred_proba = modelo_final.predict_proba(X_test)\n",
    "        y_pred = modelo_final.predict(X_test)\n",
    "    \n",
    "    # Evaluación\n",
    "    etiquetas_clases = ['Bajo', 'Medio', 'Alto']\n",
    "    matriz_conf, _ = matriz_confusion_manual(y_test, y_pred, etiquetas=[0, 1, 2])\n",
    "    metricas_clase = precision_recall_f1_por_clase(matriz_conf)\n",
    "    \n",
    "    # a. Graficar matriz de confusión\n",
    "    graficar_matriz_confusion(matriz_conf, etiquetas_clases, nombre_modelo)\n",
    "    \n",
    "    # b. Calcular macro precision y recall\n",
    "    macro_precision = np.mean([v['precision'] for v in metricas_clase.values()])\n",
    "    macro_recall = np.mean([v['recall'] for v in metricas_clase.values()])\n",
    "    \n",
    "    # c. Añadir todas las métricas a los resultados\n",
    "    resultados_finales[nombre_modelo] = {\n",
    "        'Precision (Macro)': macro_precision,\n",
    "        'Recall (Macro)': macro_recall,\n",
    "        'Balanced Accuracy': balanced_accuracy_manual(matriz_conf),\n",
    "        'Macro F1-Score': macro_f1_score(metricas_clase),\n",
    "        'Weighted F1-Score': weighted_f1_score(metricas_clase, matriz_conf),\n",
    "        'AUC-ROC (Macro)': roc_auc_manual(y_test, y_pred_proba),\n",
    "        'PR-AUC (Macro)': pr_auc_manual(y_test, y_pred_proba)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n--- Resultados para {nombre_modelo} ---\")\n",
    "    print(pd.DataFrame([resultados_finales[nombre_modelo]]).T)\n",
    "    \n",
    "    # Guardar modelo\n",
    "    if not os.path.exists('../models'): os.makedirs('../models')\n",
    "    joblib.dump(modelo_final, f'../models/{nombre_modelo.lower()}_final.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tabla Comparativa de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados = pd.DataFrame(resultados_finales).T\n",
    "df_resultados.index.name = 'Modelo'\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TABLA COMPARATIVA FINAL DE MODELOS\")\n",
    "print(\"=\"*50)\n",
    "display(df_resultados.style.background_gradient(cmap='viridis', axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
