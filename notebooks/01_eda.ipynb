{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0777b6b1",
   "metadata": {},
   "source": [
    "# Análisis Exploratorio de Datos (EDA)\n",
    "## Classification Project: Predicting Default Risk in Commercial Loans\n",
    "\n",
    "**Objetivo:** Construir un modelo de clasificación multiclase para predecir el nivel de riesgo de impago de clientes que solicitan un préstamo comercial.\n",
    "\n",
    "**Clases objetivo:**\n",
    "- 0: Bajo riesgo\n",
    "- 1: Riesgo medio  \n",
    "- 2: Alto riesgo\n",
    "\n",
    "**Dataset:** 20,000 instancias con 35 características divididas en:\n",
    "- Información Financiera (15 features)\n",
    "- Historial de Pagos (10 features)\n",
    "- Datos Demográficos y Comportamiento (10 features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ded110",
   "metadata": {},
   "source": [
    "## 1. Setup y Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6caf19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Configurar paths\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Configurar matplotlib\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Importar funciones personalizadas\n",
    "from data.loader import (\n",
    "    load_training_data, \n",
    "    load_test_data, \n",
    "    get_feature_info, \n",
    "    separate_features_target,\n",
    "    encode_target_labels,\n",
    "    check_missing_values\n",
    ")\n",
    "\n",
    "print(\"Librerías importadas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c01ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos de entrenamiento y prueba\n",
    "train_data = load_training_data('../data/raw/datos_entrenamiento_riesgo.csv')\n",
    "test_data = load_test_data('../data/raw/datos_prueba_riesgo.csv')\n",
    "\n",
    "print(f\"Datos de entrenamiento: {train_data.shape}\")\n",
    "print(f\"Datos de prueba: {test_data.shape}\")\n",
    "\n",
    "# Mostrar información básica\n",
    "print(\"\\n--- Información del Dataset de Entrenamiento ---\")\n",
    "print(train_data.info())\n",
    "\n",
    "print(\"\\n--- Primeras 5 filas ---\")\n",
    "display(train_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352babce",
   "metadata": {},
   "source": [
    "## 2. Análisis de la Variable Objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573c121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de distribución de clases\n",
    "target_counts = train_data['nivel_riesgo'].value_counts()\n",
    "target_percentages = train_data['nivel_riesgo'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Distribución de clases:\")\n",
    "print(f\"Bajo:  {target_counts['Bajo']:,} ({target_percentages['Bajo']:.1f}%)\")\n",
    "print(f\"Medio: {target_counts['Medio']:,} ({target_percentages['Medio']:.1f}%)\")\n",
    "print(f\"Alto:  {target_counts['Alto']:,} ({target_percentages['Alto']:.1f}%)\")\n",
    "\n",
    "# Visualización\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Gráfico de barras\n",
    "target_counts.plot(kind='bar', ax=ax1, color=['green', 'orange', 'red'])\n",
    "ax1.set_title('Distribución de Clases - Conteo')\n",
    "ax1.set_xlabel('Nivel de Riesgo')\n",
    "ax1.set_ylabel('Número de Instancias')\n",
    "ax1.tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Gráfico de pastel\n",
    "ax2.pie(target_counts.values, labels=target_counts.index, autopct='%1.1f%%', \n",
    "        colors=['green', 'orange', 'red'], startangle=90)\n",
    "ax2.set_title('Distribución de Clases - Porcentaje')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Verificar balance de clases\n",
    "print(f\"\\nRatio de desbalance:\")\n",
    "print(f\"Clase mayoritaria / Clase minoritaria: {target_counts.max() / target_counts.min():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a1b2ac",
   "metadata": {},
   "source": [
    "## 3. Análisis de Valores Faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49e6f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores faltantes\n",
    "missing_train = check_missing_values(train_data)\n",
    "missing_test = check_missing_values(test_data)\n",
    "\n",
    "print(\"Valores faltantes en datos de entrenamiento:\")\n",
    "if len(missing_train) > 0:\n",
    "    display(missing_train)\n",
    "else:\n",
    "    print(\"No hay valores faltantes en el dataset de entrenamiento\")\n",
    "\n",
    "print(\"\\nValores faltantes en datos de prueba:\")\n",
    "if len(missing_test) > 0:\n",
    "    display(missing_test)\n",
    "else:\n",
    "    print(\"No hay valores faltantes en el dataset de prueba\")\n",
    "\n",
    "# Verificar tipos de datos\n",
    "print(\"\\nTipos de datos:\")\n",
    "print(train_data.dtypes.value_counts())\n",
    "\n",
    "# Identificar features categóricas y numéricas\n",
    "categorical_features = train_data.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_features = train_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "if 'nivel_riesgo' in categorical_features:\n",
    "    categorical_features.remove('nivel_riesgo')\n",
    "if 'nivel_riesgo' in numerical_features:\n",
    "    numerical_features.remove('nivel_riesgo')\n",
    "\n",
    "print(f\"\\nFeatures categóricas ({len(categorical_features)}): {categorical_features}\")\n",
    "print(f\"Features numéricas ({len(numerical_features)}): {len(numerical_features)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6091a7",
   "metadata": {},
   "source": [
    "## 4. Estadísticas Descriptivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf3ec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas para features numéricas\n",
    "print(\"Estadísticas descriptivas - Features numéricas:\")\n",
    "display(train_data[numerical_features].describe())\n",
    "\n",
    "# Verificar distribuciones extremas\n",
    "print(\"\\nFeatures con alta variabilidad (CV > 1.0):\")\n",
    "numerical_stats = train_data[numerical_features].describe()\n",
    "cv_values = numerical_stats.loc['std'] / numerical_stats.loc['mean']\n",
    "high_cv_features = cv_values[cv_values > 1.0].sort_values(ascending=False)\n",
    "display(high_cv_features.head(10))\n",
    "\n",
    "print(f\"\\nRango de valores por feature:\")\n",
    "for feature in numerical_features[:10]:  # Mostrar solo los primeros 10\n",
    "    min_val = train_data[feature].min()\n",
    "    max_val = train_data[feature].max()\n",
    "    range_val = max_val - min_val\n",
    "    print(f\"{feature:30}: [{min_val:10.2f}, {max_val:10.2f}] (rango: {range_val:10.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d714fb6f",
   "metadata": {},
   "source": [
    "## 5. Análisis de Correlaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6affe41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlación\n",
    "correlation_matrix = train_data[numerical_features].corr()\n",
    "\n",
    "# Encontrar correlaciones altas entre features (>0.8)\n",
    "high_corr_pairs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.8:\n",
    "            high_corr_pairs.append((\n",
    "                correlation_matrix.columns[i], \n",
    "                correlation_matrix.columns[j], \n",
    "                correlation_matrix.iloc[i, j]\n",
    "            ))\n",
    "\n",
    "print(\"Pares de features con alta correlación (>0.8):\")\n",
    "for feat1, feat2, corr in high_corr_pairs:\n",
    "    print(f\"{feat1:30} - {feat2:30}: {corr:.3f}\")\n",
    "\n",
    "# Visualizar matriz de correlación (solo una muestra de features importantes)\n",
    "plt.figure(figsize=(16, 12))\n",
    "sample_features = numerical_features[:15]  # Primeras 15 features para visualización\n",
    "sample_corr = train_data[sample_features].corr()\n",
    "\n",
    "sns.heatmap(sample_corr, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, fmt='.2f', cbar_kws={\"shrink\": .8})\n",
    "plt.title('Matriz de Correlación - Muestra de Features Numéricas')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402e32dc",
   "metadata": {},
   "source": [
    "## 6. Análisis de Features por Categoría"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf55599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener información de features por categoría\n",
    "feature_info = get_feature_info()\n",
    "\n",
    "print(\"CATEGORÍAS DE FEATURES:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for category, features in feature_info.items():\n",
    "    if category != 'target':\n",
    "        print(f\"\\n{category.upper()} ({len(features)} features):\")\n",
    "        for i, feature in enumerate(features, 1):\n",
    "            print(f\"  {i:2d}. {feature}\")\n",
    "\n",
    "# Análisis de distribuciones por categoría de riesgo\n",
    "def plot_feature_distributions(features_list, title, n_cols=3):\n",
    "    n_features = len(features_list)\n",
    "    n_rows = (n_features + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4*n_rows))\n",
    "    axes = axes.flatten() if n_rows > 1 else [axes] if n_rows == 1 else axes\n",
    "    \n",
    "    for i, feature in enumerate(features_list[:min(9, len(features_list))]):  # Máximo 9 plots\n",
    "        if feature in train_data.columns:\n",
    "            for risk_level in ['Bajo', 'Medio', 'Alto']:\n",
    "                data_subset = train_data[train_data['nivel_riesgo'] == risk_level][feature]\n",
    "                axes[i].hist(data_subset, alpha=0.6, label=f'Riesgo {risk_level}', bins=30)\n",
    "            \n",
    "            axes[i].set_title(f'{feature}')\n",
    "            axes[i].legend()\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Ocultar ejes vacíos\n",
    "    for i in range(len(features_list), len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualizar distribuciones de features financieras\n",
    "plot_feature_distributions(feature_info['financial'][:9], \"Distribuciones - Features Financieras por Nivel de Riesgo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b059393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar distribuciones de features de historial de pagos\n",
    "plot_feature_distributions(feature_info['payment_history'][:9], \"Distribuciones - Features de Historial de Pagos por Nivel de Riesgo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e6b387",
   "metadata": {},
   "source": [
    "## 7. Análisis de Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d7addb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectar outliers usando el método IQR\n",
    "from data.loader import detect_outliers_iqr\n",
    "\n",
    "# Analizar outliers en features seleccionadas\n",
    "selected_features_outliers = ['deuda_total', 'monto_solicitado', 'patrimonio_neto', \n",
    "                             'puntuacion_credito_bureau', 'tasa_interes']\n",
    "\n",
    "print(\"ANÁLISIS DE OUTLIERS (Método IQR):\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "outlier_summary = {}\n",
    "for feature in selected_features_outliers:\n",
    "    outliers, lower_bound, upper_bound = detect_outliers_iqr(train_data, feature)\n",
    "    outlier_percentage = (len(outliers) / len(train_data)) * 100\n",
    "    \n",
    "    outlier_summary[feature] = {\n",
    "        'count': len(outliers),\n",
    "        'percentage': outlier_percentage,\n",
    "        'lower_bound': lower_bound,\n",
    "        'upper_bound': upper_bound\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{feature}:\")\n",
    "    print(f\"  Outliers: {len(outliers):,} ({outlier_percentage:.2f}%)\")\n",
    "    print(f\"  Límites: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
    "\n",
    "# Visualización de outliers con boxplots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(selected_features_outliers):\n",
    "    train_data.boxplot(column=feature, by='nivel_riesgo', ax=axes[i])\n",
    "    axes[i].set_title(f'Boxplot: {feature}')\n",
    "    axes[i].set_xlabel('Nivel de Riesgo')\n",
    "\n",
    "# Ocultar el último subplot si no se usa\n",
    "axes[-1].set_visible(False)\n",
    "\n",
    "plt.suptitle('Análisis de Outliers por Nivel de Riesgo', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0257ff50",
   "metadata": {},
   "source": [
    "## 8. Conclusiones del EDA y Próximos Pasos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b352b5",
   "metadata": {},
   "source": [
    "### Hallazgos Principales:\n",
    "\n",
    "1. **Distribución de Clases:** \n",
    "   - Verificar si hay desbalance significativo entre las clases\n",
    "   - Considerar estrategias de balanceo si es necesario\n",
    "\n",
    "2. **Calidad de Datos:**\n",
    "   - Verificar presencia de valores faltantes\n",
    "   - Identificar features con alta variabilidad\n",
    "\n",
    "3. **Correlaciones:**\n",
    "   - Identificar features altamente correlacionadas para posible eliminación\n",
    "   - Detectar relaciones importantes con la variable objetivo\n",
    "\n",
    "4. **Outliers:**\n",
    "   - Evaluar impacto de outliers en el rendimiento del modelo\n",
    "   - Decidir estrategia de tratamiento (eliminación vs transformación)\n",
    "\n",
    "### Próximos Pasos:\n",
    "\n",
    "1. **Preprocesamiento:**\n",
    "   - Normalización/estandarización de features numéricas\n",
    "   - Codificación de variables categóricas\n",
    "   - Tratamiento de outliers\n",
    "\n",
    "2. **Feature Engineering:**\n",
    "   - Creación de nuevas features\n",
    "   - Selección de features más relevantes\n",
    "   - Aplicación de PCA si es necesario\n",
    "\n",
    "3. **Modelado:**\n",
    "   - Implementación de algoritmos desde cero\n",
    "   - Validación cruzada\n",
    "   - Optimización de hiperparámetros\n",
    "\n",
    "4. **Evaluación:**\n",
    "   - Métricas específicas para clasificación multiclase\n",
    "   - Análisis de matriz de confusión\n",
    "   - Consideración de costos de clasificación errónea"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
